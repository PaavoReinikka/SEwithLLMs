{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool calling\n",
    "\n",
    "This is just a prototyping notebook for tool calling with langchain and ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "from langchain_ollama import ChatOllama, OllamaLLM\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "import logging\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "from tool_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_chat_model(\n",
    "    \"llama3.2\",\n",
    "    model_provider=\"ollama\",\n",
    "    temperature=0.5,\n",
    "    max_tokens=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = ChatOllama(model=\"llama3.2\", format=\"json\", temperature=0)\n",
    "model_with_tools = model.bind_tools(tools=get_tools())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'fetch_current_electricity_price', 'args': {}, 'id': 'c2241cf3-a86a-4a5c-9935-d0d811b3f1ea', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the current electricity price in Finland?\")]\n",
    "response = model_with_tools.invoke(messages)\n",
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'fetch_current_electricity_price',\n",
       "  'args': {},\n",
       "  'id': 'c2241cf3-a86a-4a5c-9935-d0d811b3f1ea',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"\"\"You are a helpful assistant and you can call functions to get information.\n",
    "    You can call multiple functions if necessary.\n",
    "                  \"\"\"\n",
    "                  ),\n",
    "    HumanMessage(content=\"What is the current date? Also what is current time?\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant and you can call functions to get information.\\n    You can call multiple functions if necessary.\\n                  ', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What is the current date? Also what is current time?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-04-27T19:42:01.314577523Z', 'done': True, 'done_reason': 'stop', 'total_duration': 909250109, 'load_duration': 17007963, 'prompt_eval_count': 895, 'prompt_eval_duration': 140000000, 'eval_count': 28, 'eval_duration': 316000000, 'model_name': 'llama3.2'}, id='run-3020a388-52c5-4362-be8f-3be88dce5598-0', tool_calls=[{'name': 'get_current_date', 'args': {}, 'id': '000ad38d-4401-4950-ad42-1cb0989113b8', 'type': 'tool_call'}, {'name': 'get_current_time', 'args': {}, 'id': '63a4fc11-78e5-4c55-9ba6-1b907c3d4d90', 'type': 'tool_call'}], usage_metadata={'input_tokens': 895, 'output_tokens': 28, 'total_tokens': 923}),\n",
       " ToolMessage(content='2025-04-27', name='get_current_date', tool_call_id='000ad38d-4401-4950-ad42-1cb0989113b8'),\n",
       " ToolMessage(content='22:42', name='get_current_time', tool_call_id='63a4fc11-78e5-4c55-9ba6-1b907c3d4d90')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message = model_with_tools.invoke(messages)\n",
    "messages.append(ai_message)\n",
    "for tool_call in ai_message.tool_calls:\n",
    "    selected_tool = tool_map[tool_call[\"name\"].lower()]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The current date is April 27, 2025. The current time is 10:42 PM.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-27T19:42:05.661919914Z', 'done': True, 'done_reason': 'stop', 'total_duration': 212615509, 'load_duration': 15976174, 'prompt_eval_count': 140, 'prompt_eval_duration': 4000000, 'eval_count': 23, 'eval_duration': 191000000, 'model_name': 'llama3.2'} id='run-6810b470-cf5c-4aab-985c-92cc05e4c1f7-0' usage_metadata={'input_tokens': 140, 'output_tokens': 23, 'total_tokens': 163}\n"
     ]
    }
   ],
   "source": [
    "response = model_with_tools.invoke(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# male a promt template\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant and you can call functions to get information.\"),\n",
    "        (\"human\", \"{user_input}\"),        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res=prompt.invoke({\"user_input\": \"What is the current date? Also what is current time?\"})\n",
    "#res.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res=(prompt | model_with_tools).invoke({\"user_input\": \"What is the current date? Also what is current time?\"})\n",
    "# (prompt | model_with_tools).invoke({\"user_input\": \"What is the current date? Also what is current time?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "# Set up the function to call the model\n",
    "def call_model(input_text, prompt):\n",
    "    '''\n",
    "    Calls the AI model with the provided input text and returns the response.\n",
    "\n",
    "    Args:\n",
    "        prompt (ChatPromptTemplate): The prompt template to use for the model.\n",
    "        input_text (str): The input text to send to the AI model.\n",
    "\n",
    "    Returns:\n",
    "        str: The response from the AI model.\n",
    "        prompt (ChatPromptTemplate): The updated prompt with the model response.\n",
    "    '''\n",
    "    chain = prompt | model_with_tools\n",
    "    try:\n",
    "        response = chain.invoke({\"user_input\": input_text})\n",
    "        logger.info(f\"Model response: {response}\")\n",
    "        # Check if the response contains tool calls\n",
    "        if response.tool_calls:\n",
    "            for tool_call in response.tool_calls:\n",
    "                selected_tool = tool_map[tool_call[\"name\"].lower()]\n",
    "                tool_msg = selected_tool.invoke(tool_call)\n",
    "                logger.info(f\"Tool response: {tool_msg}\")\n",
    "                # Append the tool response to the messages\n",
    "                prompt.messages.append(response)\n",
    "                prompt.messages.append(tool_msg)\n",
    "                # call the model again with the updated messages\n",
    "            return call_model(input_text, prompt)\n",
    "        else:\n",
    "            logger.info(\"No tool calls in the response.\")\n",
    "            # update the prompt with the model response\n",
    "            prompt.messages.append(response)\n",
    "            new_prompt = ChatPromptTemplate.from_messages(\n",
    "                prompt.messages + [\n",
    "                    (\"human\", \"{user_input}\"),\n",
    "                ]\n",
    "            )\n",
    "        return response, new_prompt\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error calling model: {e}\")\n",
    "        return None, prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Model response: content='' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-27T19:58:25.727514019Z', 'done': True, 'done_reason': 'stop', 'total_duration': 476496517, 'load_duration': 13563681, 'prompt_eval_count': 885, 'prompt_eval_duration': 151000000, 'eval_count': 28, 'eval_duration': 309000000, 'model_name': 'llama3.2'} id='run-35c7cd7d-c511-410c-bf75-0bcd32200f4f-0' tool_calls=[{'name': 'get_current_date', 'args': {}, 'id': 'ebf3a944-a37e-40ed-988c-bdb0ceefe4bf', 'type': 'tool_call'}, {'name': 'get_current_time', 'args': {}, 'id': 'be15cef8-ab82-4e0a-9ca3-a68ccd3af7a3', 'type': 'tool_call'}] usage_metadata={'input_tokens': 885, 'output_tokens': 28, 'total_tokens': 913}\n",
      "INFO:__main__:Tool response: content='2025-04-27' name='get_current_date' tool_call_id='ebf3a944-a37e-40ed-988c-bdb0ceefe4bf'\n",
      "INFO:__main__:Tool response: content='22:58' name='get_current_time' tool_call_id='be15cef8-ab82-4e0a-9ca3-a68ccd3af7a3'\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Model response: content='The current date is April 27, 2025.\\nThe current time is 10:58 PM.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-27T19:58:25.948185786Z', 'done': True, 'done_reason': 'stop', 'total_duration': 216967819, 'load_duration': 15902874, 'prompt_eval_count': 166, 'prompt_eval_duration': 5000000, 'eval_count': 23, 'eval_duration': 194000000, 'model_name': 'llama3.2'} id='run-4fbc695c-1845-49ee-a786-92159dab3748-0' usage_metadata={'input_tokens': 166, 'output_tokens': 23, 'total_tokens': 189}\n",
      "INFO:__main__:No tool calls in the response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: content='The current date is April 27, 2025.\\nThe current time is 10:58 PM.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-27T19:58:25.948185786Z', 'done': True, 'done_reason': 'stop', 'total_duration': 216967819, 'load_duration': 15902874, 'prompt_eval_count': 166, 'prompt_eval_duration': 5000000, 'eval_count': 23, 'eval_duration': 194000000, 'model_name': 'llama3.2'} id='run-4fbc695c-1845-49ee-a786-92159dab3748-0' usage_metadata={'input_tokens': 166, 'output_tokens': 23, 'total_tokens': 189}\n"
     ]
    }
   ],
   "source": [
    "input_text = \"What is the current date? Also what is the current time?\"\n",
    "response, prompt = call_model(input_text, prompt=prompt)\n",
    "if response:\n",
    "    print(f\"Response: {response}\")\n",
    "else:\n",
    "    print(\"Failed to get a response from the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant and you can call functions to get information.'), additional_kwargs={}),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['user_input'], input_types={}, partial_variables={}, template='{user_input}'), additional_kwargs={}),\n",
       " AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-04-27T19:58:25.727514019Z', 'done': True, 'done_reason': 'stop', 'total_duration': 476496517, 'load_duration': 13563681, 'prompt_eval_count': 885, 'prompt_eval_duration': 151000000, 'eval_count': 28, 'eval_duration': 309000000, 'model_name': 'llama3.2'}, id='run-35c7cd7d-c511-410c-bf75-0bcd32200f4f-0', tool_calls=[{'name': 'get_current_date', 'args': {}, 'id': 'ebf3a944-a37e-40ed-988c-bdb0ceefe4bf', 'type': 'tool_call'}, {'name': 'get_current_time', 'args': {}, 'id': 'be15cef8-ab82-4e0a-9ca3-a68ccd3af7a3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 885, 'output_tokens': 28, 'total_tokens': 913}),\n",
       " ToolMessage(content='2025-04-27', name='get_current_date', tool_call_id='ebf3a944-a37e-40ed-988c-bdb0ceefe4bf'),\n",
       " AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-04-27T19:58:25.727514019Z', 'done': True, 'done_reason': 'stop', 'total_duration': 476496517, 'load_duration': 13563681, 'prompt_eval_count': 885, 'prompt_eval_duration': 151000000, 'eval_count': 28, 'eval_duration': 309000000, 'model_name': 'llama3.2'}, id='run-35c7cd7d-c511-410c-bf75-0bcd32200f4f-0', tool_calls=[{'name': 'get_current_date', 'args': {}, 'id': 'ebf3a944-a37e-40ed-988c-bdb0ceefe4bf', 'type': 'tool_call'}, {'name': 'get_current_time', 'args': {}, 'id': 'be15cef8-ab82-4e0a-9ca3-a68ccd3af7a3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 885, 'output_tokens': 28, 'total_tokens': 913}),\n",
       " ToolMessage(content='22:58', name='get_current_time', tool_call_id='be15cef8-ab82-4e0a-9ca3-a68ccd3af7a3'),\n",
       " AIMessage(content='The current date is April 27, 2025.\\nThe current time is 10:58 PM.', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-04-27T19:58:25.948185786Z', 'done': True, 'done_reason': 'stop', 'total_duration': 216967819, 'load_duration': 15902874, 'prompt_eval_count': 166, 'prompt_eval_duration': 5000000, 'eval_count': 23, 'eval_duration': 194000000, 'model_name': 'llama3.2'}, id='run-4fbc695c-1845-49ee-a786-92159dab3748-0', usage_metadata={'input_tokens': 166, 'output_tokens': 23, 'total_tokens': 189}),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['user_input'], input_types={}, partial_variables={}, template='{user_input}'), additional_kwargs={})]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Model response: content='' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-27T19:59:08.095014072Z', 'done': True, 'done_reason': 'stop', 'total_duration': 476966826, 'load_duration': 15581881, 'prompt_eval_count': 1084, 'prompt_eval_duration': 152000000, 'eval_count': 22, 'eval_duration': 298000000, 'model_name': 'llama3.2'} id='run-339198b2-4b4e-4f5d-810f-6746469ad80a-0' tool_calls=[{'name': 'subtract', 'args': {'a': '12', 'b': '337'}, 'id': '66fb2750-d489-4aa5-9cb7-e976d0a7978f', 'type': 'tool_call'}] usage_metadata={'input_tokens': 1084, 'output_tokens': 22, 'total_tokens': 1106}\n",
      "INFO:__main__:Tool response: content='-325' name='subtract' tool_call_id='66fb2750-d489-4aa5-9cb7-e976d0a7978f'\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Model response: content='The result of 12.34 - 337.1 is -324.66 (rounded to two decimal places).' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-27T19:59:08.334539482Z', 'done': True, 'done_reason': 'stop', 'total_duration': 235939354, 'load_duration': 16162216, 'prompt_eval_count': 313, 'prompt_eval_duration': 3000000, 'eval_count': 25, 'eval_duration': 212000000, 'model_name': 'llama3.2'} id='run-9d955144-2478-4959-b1d7-6432f5c21e76-0' usage_metadata={'input_tokens': 313, 'output_tokens': 25, 'total_tokens': 338}\n",
      "INFO:__main__:No tool calls in the response.\n"
     ]
    }
   ],
   "source": [
    "response, prompt = call_model(\"what is 12.34 - 337.1 using a tool?\", prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant and you can call functions to get information.'), additional_kwargs={}),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['user_input'], input_types={}, partial_variables={}, template='{user_input}'), additional_kwargs={}),\n",
       " AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-04-27T19:58:25.727514019Z', 'done': True, 'done_reason': 'stop', 'total_duration': 476496517, 'load_duration': 13563681, 'prompt_eval_count': 885, 'prompt_eval_duration': 151000000, 'eval_count': 28, 'eval_duration': 309000000, 'model_name': 'llama3.2'}, id='run-35c7cd7d-c511-410c-bf75-0bcd32200f4f-0', tool_calls=[{'name': 'get_current_date', 'args': {}, 'id': 'ebf3a944-a37e-40ed-988c-bdb0ceefe4bf', 'type': 'tool_call'}, {'name': 'get_current_time', 'args': {}, 'id': 'be15cef8-ab82-4e0a-9ca3-a68ccd3af7a3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 885, 'output_tokens': 28, 'total_tokens': 913}),\n",
       " ToolMessage(content='2025-04-27', name='get_current_date', tool_call_id='ebf3a944-a37e-40ed-988c-bdb0ceefe4bf'),\n",
       " AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-04-27T19:58:25.727514019Z', 'done': True, 'done_reason': 'stop', 'total_duration': 476496517, 'load_duration': 13563681, 'prompt_eval_count': 885, 'prompt_eval_duration': 151000000, 'eval_count': 28, 'eval_duration': 309000000, 'model_name': 'llama3.2'}, id='run-35c7cd7d-c511-410c-bf75-0bcd32200f4f-0', tool_calls=[{'name': 'get_current_date', 'args': {}, 'id': 'ebf3a944-a37e-40ed-988c-bdb0ceefe4bf', 'type': 'tool_call'}, {'name': 'get_current_time', 'args': {}, 'id': 'be15cef8-ab82-4e0a-9ca3-a68ccd3af7a3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 885, 'output_tokens': 28, 'total_tokens': 913}),\n",
       " ToolMessage(content='22:58', name='get_current_time', tool_call_id='be15cef8-ab82-4e0a-9ca3-a68ccd3af7a3'),\n",
       " AIMessage(content='The current date is April 27, 2025.\\nThe current time is 10:58 PM.', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-04-27T19:58:25.948185786Z', 'done': True, 'done_reason': 'stop', 'total_duration': 216967819, 'load_duration': 15902874, 'prompt_eval_count': 166, 'prompt_eval_duration': 5000000, 'eval_count': 23, 'eval_duration': 194000000, 'model_name': 'llama3.2'}, id='run-4fbc695c-1845-49ee-a786-92159dab3748-0', usage_metadata={'input_tokens': 166, 'output_tokens': 23, 'total_tokens': 189}),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['user_input'], input_types={}, partial_variables={}, template='{user_input}'), additional_kwargs={}),\n",
       " AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-04-27T19:58:42.623579548Z', 'done': True, 'done_reason': 'stop', 'total_duration': 442513430, 'load_duration': 15681858, 'prompt_eval_count': 1009, 'prompt_eval_duration': 145000000, 'eval_count': 22, 'eval_duration': 272000000, 'model_name': 'llama3.2'}, id='run-afec8001-7302-4cc1-9f72-2e66ca3b2e46-0', tool_calls=[{'name': 'multiply', 'args': {'a': '16', 'b': '3'}, 'id': '8aac1148-357c-441a-a9fb-1e9e7888755a', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1009, 'output_tokens': 22, 'total_tokens': 1031}),\n",
       " ToolMessage(content='48', name='multiply', tool_call_id='8aac1148-357c-441a-a9fb-1e9e7888755a'),\n",
       " AIMessage(content='The result of 16 * 3 is 48.', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-04-27T19:58:42.757804881Z', 'done': True, 'done_reason': 'stop', 'total_duration': 131238347, 'load_duration': 15119618, 'prompt_eval_count': 237, 'prompt_eval_duration': 3000000, 'eval_count': 13, 'eval_duration': 109000000, 'model_name': 'llama3.2'}, id='run-fcf553dd-188e-4318-b1b8-8e290e87e3a7-0', usage_metadata={'input_tokens': 237, 'output_tokens': 13, 'total_tokens': 250}),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['user_input'], input_types={}, partial_variables={}, template='{user_input}'), additional_kwargs={}),\n",
       " AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-04-27T19:59:08.095014072Z', 'done': True, 'done_reason': 'stop', 'total_duration': 476966826, 'load_duration': 15581881, 'prompt_eval_count': 1084, 'prompt_eval_duration': 152000000, 'eval_count': 22, 'eval_duration': 298000000, 'model_name': 'llama3.2'}, id='run-339198b2-4b4e-4f5d-810f-6746469ad80a-0', tool_calls=[{'name': 'subtract', 'args': {'a': '12', 'b': '337'}, 'id': '66fb2750-d489-4aa5-9cb7-e976d0a7978f', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1084, 'output_tokens': 22, 'total_tokens': 1106}),\n",
       " ToolMessage(content='-325', name='subtract', tool_call_id='66fb2750-d489-4aa5-9cb7-e976d0a7978f'),\n",
       " AIMessage(content='The result of 12.34 - 337.1 is -324.66 (rounded to two decimal places).', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-04-27T19:59:08.334539482Z', 'done': True, 'done_reason': 'stop', 'total_duration': 235939354, 'load_duration': 16162216, 'prompt_eval_count': 313, 'prompt_eval_duration': 3000000, 'eval_count': 25, 'eval_duration': 212000000, 'model_name': 'llama3.2'}, id='run-9d955144-2478-4959-b1d7-6432f5c21e76-0', usage_metadata={'input_tokens': 313, 'output_tokens': 25, 'total_tokens': 338}),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['user_input'], input_types={}, partial_variables={}, template='{user_input}'), additional_kwargs={})]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The result of 12.34 - 337.1 is -324.66 (rounded to two decimal places).'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
